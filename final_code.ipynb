{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import scipy\n",
    "from scipy.io import loadmat\n",
    "from scipy.sparse import diags\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import csc_matrix\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from scipy.linalg import expm\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "scaler = MinMaxScaler()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device1 = torch.device('cpu')\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# torch.manual_seed(1)\n",
    "# torch.cuda.manual_seed_all(1)\n",
    "# np.random.seed(1)\n",
    "\n",
    "\n",
    "def error_point(prep, real):\n",
    "    prep_0 = prep\n",
    "    error_point = np.array([], dtype=int)\n",
    "    prep_full_label = np.setdiff1d(np.unique(prep), np.array([-1]))\n",
    "    real_full_label = np.setdiff1d(np.unique(real), np.array([-1]))\n",
    "    nonnoise_index = np.intersect1d(\n",
    "        np.where(prep != -1)[0],\n",
    "        np.where(real != -1)[0])\n",
    "    real = real[nonnoise_index]\n",
    "    prep = prep[nonnoise_index]\n",
    "    real_label = np.unique(real)\n",
    "    prep_label = np.unique(prep)\n",
    "    n = len(real_label)\n",
    "    n_1 = len(prep_label)\n",
    "    reallogic = (np.reshape(np.repeat(real, n), [len(real), n])\n",
    "                 == real_label).T + 0\n",
    "    preplogic = (np.reshape(np.repeat(prep, n_1), [len(prep), n_1])\n",
    "                 == prep_label).T + 0\n",
    "    interset_matrix = reallogic @ preplogic.T\n",
    "    x = cp.Variable((n, n_1), integer=True)\n",
    "    obj = cp.Minimize(-cp.sum(cp.multiply(interset_matrix, x)))\n",
    "    con = [\n",
    "        0 <= x, x <= 1,\n",
    "        cp.sum(x, axis=0, keepdims=True) == 1,\n",
    "        cp.sum(x, axis=1, keepdims=True) <= 1\n",
    "    ]\n",
    "    prob = cp.Problem(obj, con)\n",
    "    prob.solve('GLPK_MI')\n",
    "    index = np.array(np.where(x.value == 1))\n",
    "    add_index = np.array([\n",
    "        np.setdiff1d(real_full_label, real_label[index[0, :]]),\n",
    "        np.setdiff1d(prep_full_label, prep_label[index[1, :]])\n",
    "    ],\n",
    "                         dtype=int)\n",
    "    prep0 = np.setdiff1d(prep_full_label, prep_label[index[1, :]])\n",
    "    index = np.concatenate((index, add_index), axis=1)\n",
    "\n",
    "    related_index = []\n",
    "    for i in range(n):\n",
    "        if i < n_1:\n",
    "            real_iter_index = np.where(real == np.unique(real)[index[0, i]])[0]\n",
    "            prep_iter_index = np.where(prep == np.unique(prep)[index[1, i]])[0]\n",
    "            pp_index = np.where(prep_0 == np.unique(prep)[index[1, i]])[0]\n",
    "            related_index.append(pp_index)\n",
    "        else:\n",
    "            real_iter_index = np.where(real == np.unique(real)[index[0, i]])[0]\n",
    "            prep_iter_index = np.where(prep == np.unique(prep0)[i - n_1])[0]\n",
    "            pp_index = np.where(prep_0 == np.unique(prep0)[i - n_1])[0]\n",
    "            related_index.append(pp_index)\n",
    "        error_point_i = np.setdiff1d(real_iter_index, prep_iter_index)\n",
    "        error_point = np.union1d(error_point, error_point_i)\n",
    "    for i in range(n):\n",
    "        prep_0[related_index[i]] = np.ones(len(\n",
    "            related_index[i])) * np.unique(real)[index[0, i]]\n",
    "    error_point = nonnoise_index[error_point]\n",
    "    return error_point, prep_0\n",
    "\n",
    "\n",
    "class load_data(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        data = loadmat(dataset)\n",
    "        X = data['data'][0]\n",
    "        self.y = data['truelabel'][0][0].reshape(-1)\n",
    "        self.x = []\n",
    "        if isinstance(X[0], csr_matrix) or isinstance(\n",
    "                X[0], csc_matrix) or isinstance(X[0], coo_matrix):\n",
    "            for i in range(len(X)):\n",
    "                self.x.append(X[i].toarray())\n",
    "        else:\n",
    "            for i in range(len(X)):\n",
    "                self.x.append(X[i])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(np.array(self.x[idx])), torch.from_numpy(\n",
    "            np.array(self.y[idx])), torch.from_numpy(np.array(idx))\n",
    "\n",
    "\n",
    "def torch_intersect1d(t1: torch.Tensor, t2: torch.Tensor):\n",
    "    # NOTE: requires t1, t2 to be unique 1D Tensor in advance.\n",
    "    # Method: based on unique's count\n",
    "    num_t1, num_t2 = t1.numel(), t2.numel()\n",
    "    u, inv, cnt = torch.unique(torch.cat([t1, t2]),\n",
    "                               return_counts=True,\n",
    "                               return_inverse=True)\n",
    "\n",
    "    cnt_12 = cnt[inv]\n",
    "    cnt_t1, cnt_t2 = cnt_12[:num_t1], cnt_12[num_t1:]\n",
    "    m_t1 = (cnt_t1 == 2)\n",
    "    inds_t1 = m_t1.nonzero()[..., 0]\n",
    "    inds_t1_exclusive = (~m_t1).nonzero()[..., 0]\n",
    "    inds_t2_exclusive = (cnt_t2 == 1).nonzero()[..., 0]\n",
    "\n",
    "    intersection = t1[inds_t1]\n",
    "    t1_exclusive = t1[inds_t1_exclusive]\n",
    "    t2_exclusive = t2[inds_t2_exclusive]\n",
    "    return intersection, t1_exclusive, t2_exclusive\n",
    "\n",
    "\n",
    "def NormalizeData(data):\n",
    "    data = data.T\n",
    "    if np.sum(np.sum(data**2, axis=0) < 0) > 0:\n",
    "        print((data**2)[np.where(np.sum(data**2, axis=0) < 0)[0], :])\n",
    "        print(np.where(np.sum(np.abs(data), axis=0) < 0)[0])\n",
    "        mm = np.maximum(np.sum(np.abs(data), axis=0), 10**-14)\n",
    "\n",
    "        data = data * diags(mm**-1, 0)\n",
    "    else:\n",
    "        mm = np.maximum(np.sum(data**2, axis=0), 10**-14)\n",
    "        data = data * diags(mm**-0.5, 0)\n",
    "    return data.T\n",
    "\n",
    "\n",
    "def comnFun(K, sigma):\n",
    "    nSmp = K[0].shape[0]\n",
    "    view_num = len(K)\n",
    "    KC = np.zeros([nSmp, nSmp])\n",
    "    for i in range(view_num):\n",
    "        KC = KC + sigma[i] * K[i]\n",
    "    return KC\n",
    "\n",
    "\n",
    "def kcenter(K):\n",
    "    n = K.shape[0]\n",
    "    D = np.sum(K, axis=0) / n\n",
    "    E = np.sum(D) / n\n",
    "    J = D.reshape([n, 1])\n",
    "    K = K - J - J.T + E * np.ones([n, n])\n",
    "    K = 0.5 * (K + K.T)\n",
    "    return K\n",
    "\n",
    "\n",
    "def kernel_regularization(K):\n",
    "    G = K + K.T / 2\n",
    "    G = G.detach().cpu().numpy()\n",
    "    D, V = np.linalg.eig(G)\n",
    "    D = D * (D > 10**-14)\n",
    "    G = (V * diags(D, 0)) @ V.T\n",
    "    G = (G + G.T) / 2\n",
    "    return torch.tensor(G).to(device)\n",
    "\n",
    "\n",
    "def generateNeighborhood(X, k):\n",
    "    X = np.copy(X)\n",
    "    knn = []\n",
    "    min_X = np.min(X)\n",
    "    for i in range(k + 1):\n",
    "        index = np.argmax(X, axis=1)\n",
    "        knn.append(index)\n",
    "        # 将近邻元素设置为比对角元素大的值，以便寻找反向k近邻\n",
    "        X[np.arange(X.shape[0]), index] = np.array([min_X - 1] * X.shape[0])\n",
    "    return X < min_X, np.array(knn, dtype=np.int32).T\n",
    "\n",
    "\n",
    "def adapted_neighbor(X, min_k, k):\n",
    "    X = np.copy(X)\n",
    "    min_X = np.min(X)\n",
    "    for knn_k in range(int(0.5 * X.shape[0])):\n",
    "        index = np.argmax(X, axis=1)\n",
    "        X[np.arange(X.shape[0]), index] = np.array([min_X - 1] * X.shape[0])\n",
    "        logic_nn = X < min_X\n",
    "        logic_nn = logic_nn * logic_nn.T\n",
    "        if np.mean(np.sum(logic_nn, axis=1)) > min_k:\n",
    "            print((np.sum(np.sum(logic_nn, axis=1)) / X.shape[0]), knn_k)\n",
    "            return X < min_X\n",
    "        if knn_k >= max(int(.5 * X.shape[0]), 5):\n",
    "            print((np.sum(np.sum(logic_nn, axis=1)) / X.shape[0]), knn_k,\n",
    "                  max(int(.5 * X.shape[0]), 5))\n",
    "            return X < min_X\n",
    "    return X < min_X\n",
    "\n",
    "\n",
    "def knn_mean_X(X, knn):\n",
    "    knn_X = X[knn]\n",
    "    return np.sum(knn_X, axis=1) / np.maximum(np.sum(knn_X > 0, axis=1),\n",
    "                                              np.ones(X[0].shape))\n",
    "\n",
    "\n",
    "def compute_init_loss(K, view_K, X_bar, model):\n",
    "    loss0 = 0\n",
    "    loss1 = 0\n",
    "    loss_param = 0\n",
    "    criterion = nn.MSELoss()\n",
    "    for i in range(len(view_K)):\n",
    "        for param in model[i].parameters():\n",
    "            if param is model[i].kernel_weights:\n",
    "                continue\n",
    "            loss_param += torch.norm(param, p=1) / max(param.size())\n",
    "        loss0 = loss0 + criterion(view_K[i].view(-1), K[i].view(-1))\n",
    "        loss1 = loss1 + torch.sum(\n",
    "            torch.log1p(X_bar[i]) + torch.log1p(1 - X_bar[i]))\n",
    "    return [loss0, loss1, loss_param]\n",
    "\n",
    "\n",
    "def kernelkmeans(K, n_clusters):\n",
    "    _, H = eigsh(K, k=n_clusters, which='LA')\n",
    "    return H\n",
    "\n",
    "\n",
    "# the structure of neural network\n",
    "class connectivity(nn.Module):\n",
    "    def __init__(self, options):\n",
    "        super(connectivity, self).__init__()\n",
    "        self.options = options\n",
    "        self.activ = torch.nn.Sigmoid()\n",
    "        self.activ1 = torch.nn.ReLU()\n",
    "        self.activ2 = torch.nn.Tanh()\n",
    "        self.matrix = torch.nn.Parameter(1 / (options.nSmp)**.5 * torch.zeros(\n",
    "            [options.nSmp, options.n_clusters], dtype=torch.float32))\n",
    "        self.layerencode = nn.ModuleList([\n",
    "            nn.Linear(options.layer_width_c[i],\n",
    "                      options.layer_width_c[i + 1],\n",
    "                      bias=False,\n",
    "                      dtype=torch.float32)\n",
    "            for i in range(len(options.layer_width_c) - 1)\n",
    "        ])\n",
    "\n",
    "        for i in range(len(options.layer_width_c) - 1):\n",
    "            nn.init.kaiming_normal_(self.layerencode[i].weight,\n",
    "                                    nonlinearity='relu')\n",
    "\n",
    "    def forward(self, knn_list):\n",
    "        X = []\n",
    "        for i in range(self.options.view_num):\n",
    "            X.append(knn_list[i])\n",
    "            for j in range(len(self.layerencode)):\n",
    "                if j < len(self.layerencode) - 1:\n",
    "                    X[i] = self.activ1(X[i] @ self.layerencode[j].weight.T)\n",
    "                else:\n",
    "                    X[i] = X[i] @ self.layerencode[j].weight.T\n",
    "\n",
    "        return X\n",
    "\n",
    "\n",
    "def init_Kernel_train(y, view_K, options):\n",
    "    knn_list = []\n",
    "    optimizers = {}\n",
    "    init_maxiter = options.maxIter\n",
    "\n",
    "    for i in range(options.view_num):\n",
    "        knn_list.append(\n",
    "            torch.tensor(view_K[i], dtype=torch.float32, device=device))\n",
    "    connect_kernel = connectivity(options).to(device)\n",
    "    # initial optimizer ------------------------------------------------------------------------------------------------------------\n",
    "    optimizers[\"optimizer_connectivity\"] = optim.Adam(\n",
    "        [i.weight for i in connect_kernel.layerencode], lr=1e-3)\n",
    "    sv = [0.5] * (options.n_clusters)\n",
    "    singular_value = [\n",
    "        torch.tensor(sv,\n",
    "                     dtype=torch.float32,\n",
    "                     device=device,\n",
    "                     requires_grad=True) for i in range(options.view_num)\n",
    "    ]\n",
    "    optimizers[\"optimizer_singular\"] = optim.Adam(singular_value, lr=1e-3)\n",
    "\n",
    "    best_label = np.zeros([3, options.nSmp], dtype=np.int32)\n",
    "    best_accurancy = [0] * 3\n",
    "    knn_temp_list = []\n",
    "    knn_temp_max_list = []\n",
    "    knn_temp_min_list = []\n",
    "\n",
    "    # normalize K --------------------------------------------------------------------------------------------------------------------\n",
    "    for i in range(options.view_num):\n",
    "        logic_knn = torch.tensor(1. * options.knn[i],\n",
    "                                 dtype=torch.float32,\n",
    "                                 device=device)\n",
    "        knn_temp_list.append(knn_list[i] * (1. *\n",
    "                                            (logic_knn + logic_knn.T) > 0))\n",
    "\n",
    "        knn_temp_min_list.append(knn_list[i] * (1. *\n",
    "                                                (logic_knn * logic_knn.T) > 0))\n",
    "\n",
    "        del logic_knn\n",
    "        torch.cuda.empty_cache()\n",
    "        D = ((torch.maximum(\n",
    "            torch.abs(torch.sum(knn_temp_min_list[i], dim=1)),\n",
    "            torch.ones(knn_temp_min_list[i].shape[0],\n",
    "                       dtype=torch.float32).to(device) *\n",
    "            1e-15)**-1)**.5).unsqueeze(1)\n",
    "        knn_temp_min_list[i] = knn_temp_min_list[i] * D * D.T\n",
    "\n",
    "        D = ((torch.maximum(\n",
    "            torch.abs(torch.sum(knn_temp_list[i], dim=1)),\n",
    "            torch.ones(knn_temp_list[i].shape[0],\n",
    "                       dtype=torch.float32).to(device) *\n",
    "            1e-15)**-1)**.5).unsqueeze(1)\n",
    "        knn_temp_list[i] = knn_temp_list[i] * D * D.T\n",
    "\n",
    "        knn_temp_max_list.append(knn_temp_list[i] @ knn_temp_list[i])\n",
    "\n",
    "    del D, knn_list\n",
    "    torch.cuda.empty_cache()\n",
    "    if options.alpha == 0:\n",
    "        del knn_temp_min_list\n",
    "        torch.cuda.empty_cache()\n",
    "    if options.beta == 0:\n",
    "        del knn_temp_max_list\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    old_loss = 1e15\n",
    "    old_rank = 0\n",
    "    old_inter_loss = -1e15\n",
    "    object_function = np.zeros(options.maxIter - options.init_time)\n",
    "    for epoch in range(init_maxiter):\n",
    "        loss_init = 0\n",
    "        loss_list = []\n",
    "        reg_loss = 0\n",
    "        # compute $\\Phi$ ------------------------------------------------------------------------------------------\n",
    "        X_view = connect_kernel(knn_temp_list)\n",
    "\n",
    "        for j in range(len(options.layer_width_c) - 1):\n",
    "            reg_loss += 0.5 * torch.norm(\n",
    "                connect_kernel.layerencode[j].weight)**2\n",
    "\n",
    "        orx_loss = []\n",
    "\n",
    "        connected_matrix = (connect_kernel.matrix @ connect_kernel.matrix.T)\n",
    "\n",
    "        view_loss = []\n",
    "        connect_loss = []\n",
    "        view_loss_temp = []\n",
    "        view_loss_temp_1 = []\n",
    "\n",
    "        # initial grad of $\\Phi$ -----------------------------------------------------------------------------------\n",
    "        X_view_orth_grad = torch.zeros_like(X_view[0],\n",
    "                                            device=device,\n",
    "                                            dtype=torch.float32)\n",
    "        X_view_grad = torch.zeros_like(X_view[0],\n",
    "                                       device=device,\n",
    "                                       dtype=torch.float32)\n",
    "\n",
    "        for i in range(options.view_num):\n",
    "            connect_view_k = ((X_view[i] * singular_value[i]) @ X_view[i].T)\n",
    "\n",
    "            X_view_orth_grad = 4 * (X_view[i] @ X_view[i].T @ X_view[i] -\n",
    "                                    X_view[i])\n",
    "\n",
    "            # compute $L_{connect}$ --------------------------------------------------------------------------------\n",
    "            view_loss_temp.append(\n",
    "                1 / (1 + options.alpha + options.beta) *\n",
    "                torch.trace(X_view[i].T @ (X_view[i] * singular_value[i])\n",
    "                            @ X_view[i].T @ (X_view[i] * singular_value[i]) -\n",
    "                            2 * X_view[i].T @ knn_temp_list[i] @ (\n",
    "                                X_view[i] * singular_value[i])))\n",
    "\n",
    "            X_view_grad = 2 / (1 + options.alpha + options.beta) * (\n",
    "                2 * connect_view_k - knn_temp_list[i] -\n",
    "                knn_temp_list[i].T) @ (X_view[i] * singular_value[i])\n",
    "\n",
    "            if options.alpha > 0:\n",
    "                # compute $L_{connect}$ ----------------------------------------------------------------------------\n",
    "                view_loss_temp_1.append(\n",
    "                    options.alpha / (1 + options.alpha + options.beta) *\n",
    "                    torch.trace(\n",
    "                        X_view[i].T @ (X_view[i] * singular_value[i]**.5)\n",
    "                        @ X_view[i].T @ (X_view[i] * singular_value[i]**.5) -\n",
    "                        2 * X_view[i].T @ knn_temp_min_list[i] @ (\n",
    "                            X_view[i] * singular_value[i]**.5)))\n",
    "\n",
    "                X_view_grad += 2 * options.alpha / (\n",
    "                    1 + options.alpha + options.beta) * (\n",
    "                        2 * (X_view[i] * singular_value[i]**.5) @ X_view[i].T -\n",
    "                        knn_temp_min_list[i] - knn_temp_min_list[i].T) @ (\n",
    "                            X_view[i] * singular_value[i]**.5)\n",
    "            if options.beta > 0:\n",
    "                # compute $L_{connect}$ ------------------------------------------------------------------------------\n",
    "                view_loss_temp_1.append(\n",
    "                    options.alpha / (1 + options.alpha + options.beta) *\n",
    "                    torch.trace(\n",
    "                        X_view[i].T @ (X_view[i] * singular_value[i]**2)\n",
    "                        @ X_view[i].T @ (X_view[i] * singular_value[i]**2) -\n",
    "                        2 * X_view[i].T @ knn_temp_max_list[i] @ (\n",
    "                            X_view[i] * singular_value[i]**2)))\n",
    "\n",
    "                X_view_grad += 2 * options.beta / (\n",
    "                    1 + options.alpha + options.beta) * (\n",
    "                        2 * (X_view[i] * singular_value[i]**2) @ X_view[i].T -\n",
    "                        knn_temp_max_list[i] -\n",
    "                        knn_temp_max_list[i].T) @ (X_view[i] *\n",
    "                                                   (singular_value[i]**2))\n",
    "            # LCP modal ------------------------------------------------------------------------------------------------\n",
    "            if (epoch > options.init_time):\n",
    "                parents_index = (connect_view_k).detach().clone()\n",
    "\n",
    "                diag = ((torch.maximum(\n",
    "                    torch.diag(parents_index).detach(),\n",
    "                    torch.ones(\n",
    "                        options.nSmp, device=device, dtype=torch.float32) *\n",
    "                    1e-15))).detach().unsqueeze(1)\n",
    "\n",
    "                connectedness_matrix = parents_index / diag.T\n",
    "                del diag\n",
    "                torch.cuda.empty_cache()\n",
    "                connectedness = torch.sum(connectedness_matrix, dim=1)\n",
    "                connectedness = (torch.maximum(\n",
    "                    torch.ones(\n",
    "                        options.nSmp, device=device, dtype=torch.float32) *\n",
    "                    torch.min(connectedness[connectedness > 0]),\n",
    "                    torch.sum(connectedness_matrix, dim=1))).unsqueeze(1)\n",
    "\n",
    "                neighbor_peak = torch.tensor(\n",
    "                    1, device=device,\n",
    "                    dtype=torch.float32) * (connectedness.repeat(\n",
    "                        1, options.nSmp) < connectedness.T)\n",
    "\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "                neighbor_peak = neighbor_peak * (\n",
    "                    (connectedness_matrix) > torch.sort(\n",
    "                        torch.max(neighbor_peak * connectedness_matrix,\n",
    "                                  dim=1).values).values[options.peak_num - 1])\n",
    "\n",
    "                neighbor_peak_index = torch.where(\n",
    "                    torch.sum(neighbor_peak, dim=1) == 0)[0]\n",
    "                neighbor_peak[neighbor_peak_index,\n",
    "                              neighbor_peak_index] = torch.ones(\n",
    "                                  len(neighbor_peak_index),\n",
    "                                  device=device,\n",
    "                                  dtype=torch.float32)\n",
    "\n",
    "                parents_index = neighbor_peak * parents_index\n",
    "                del neighbor_peak, connectedness_matrix, neighbor_peak_index\n",
    "\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "                D = ((torch.maximum(\n",
    "                    torch.norm(parents_index, dim=1, p=1),\n",
    "                    torch.ones(\n",
    "                        options.nSmp, device=device, dtype=torch.float32) *\n",
    "                    1e-15))).detach().unsqueeze(1)\n",
    "\n",
    "                parents_index = (parents_index / D)\n",
    "\n",
    "                del connectedness\n",
    "                # compute $L_{LCP}$ ----------------------------------------------------------------------------------\n",
    "                connect_loss.append(\n",
    "                    torch.sum(\n",
    "                        torch.norm(parents_index @ X_view[i].detach() -\n",
    "                                   X_view[i],\n",
    "                                   dim=1)**2))\n",
    "\n",
    "                X_view_grad += 1 * 2 * options.gamma * (\n",
    "                    X_view[i] + (parents_index.T @ parents_index -\n",
    "                                 parents_index - parents_index.T) @ X_view[i])\n",
    "                del parents_index\n",
    "                # compute $L_{fusion}$ ----------------------------------------------------------------------------------\n",
    "                connect_loss.append(\n",
    "                    options.con * (1 + options.gamma) / options.gamma *\n",
    "                    torch.norm(X_view[i] * singular_value[i] -\n",
    "                               connect_kernel.matrix.detach())**2)\n",
    "\n",
    "                X_view_grad += options.con * 2. * (\n",
    "                    1 + options.gamma) * (X_view[i] * singular_value[i] -\n",
    "                                          connect_kernel.matrix).detach()\n",
    "\n",
    "                if torch.trace(connect_view_k) > options.n_clusters:\n",
    "                    connect_loss.append((torch.trace(\n",
    "                        X_view[i].T @ (X_view[i] * singular_value[i])) -\n",
    "                                         options.n_clusters))\n",
    "                    X_view_grad += 2 * (options.gamma) * (X_view[i] *\n",
    "                                                          singular_value[i])\n",
    "                elif torch.trace(connect_view_k) < options.n_clusters:\n",
    "                    connect_loss.append((options.n_clusters - torch.trace(\n",
    "                        X_view[i].T @ (X_view[i] * singular_value[i]))))\n",
    "                    X_view_grad -= 2 * (options.gamma) * (X_view[i] *\n",
    "                                                          singular_value[i])\n",
    "\n",
    "                # compute step size $\\eta$ -------------------------------------------------------------------------------------\n",
    "                norm_1 = torch.norm(X_view_grad, dim=0).detach().clone()\n",
    "                norm_2 = torch.norm(X_view_orth_grad, dim=0).detach().clone()\n",
    "                cos_value = (torch.diag(X_view_orth_grad.T @ X_view_grad) /\n",
    "                             norm_1 / norm_2).detach()\n",
    "                eta = 1. * (cos_value > options.eta) * options.eta * (norm_1 /\n",
    "                                                                      norm_2)\n",
    "                eta -= 1. * (cos_value <\n",
    "                             -options.eta) * options.eta * (norm_1 / norm_2)\n",
    "                eta += 1. * (torch.abs(cos_value) <=\n",
    "                             options.eta) * cos_value * (norm_1 / norm_2)\n",
    "                orx_loss.append(\n",
    "                    torch.trace(X_view[i].T @ X_view[i] @ X_view[i].T\n",
    "                                @ X_view[i] @ torch.diag(eta) -\n",
    "                                2 * X_view[i].T @ X_view[i] @ torch.diag(eta)))\n",
    "\n",
    "        del X_view_grad, X_view_orth_grad\n",
    "        torch.cuda.empty_cache()\n",
    "        view_loss.append(torch.stack(view_loss_temp))\n",
    "        if len(view_loss_temp_1) > 0:\n",
    "            view_loss.append(torch.stack(view_loss_temp_1))\n",
    "\n",
    "        del view_loss_temp, view_loss_temp_1\n",
    "        torch.cuda.empty_cache()\n",
    "        if len(connect_loss) > 0:\n",
    "\n",
    "            orx_loss = torch.stack(orx_loss)\n",
    "            view_loss = torch.stack(view_loss)\n",
    "            connect_loss = torch.stack(connect_loss)\n",
    "            if torch.isnan(torch.sum(view_loss) + torch.sum(connect_loss)):\n",
    "                print(view_loss, connect_loss)\n",
    "                break\n",
    "            loss_init = torch.sum(orx_loss) + torch.sum(\n",
    "                view_loss) + options.gamma * torch.sum(connect_loss)\n",
    "\n",
    "            loss_list.append([\n",
    "                orx_loss,\n",
    "                view_loss,\n",
    "                connect_loss,\n",
    "            ])\n",
    "\n",
    "            if (((torch.sum(orx_loss) + options.n_clusters * options.view_num *\n",
    "                  options.eta) < 1e-5 * options.view_num * options.n_clusters)\n",
    "                    and\n",
    "                (abs(old_loss.item() - loss_init.item()) < abs(\n",
    "                    loss_init.item()) * 1e-5)) or epoch == options.maxIter - 1:\n",
    "                print(\"converage\")\n",
    "                H = connect_kernel.matrix.detach().clone()\n",
    "\n",
    "                H_normalized = ((H / (torch.maximum(\n",
    "                    torch.norm(H, dim=1),\n",
    "                    torch.ones(\n",
    "                        options.nSmp, device=device, dtype=torch.float32) *\n",
    "                    1e-15)).unsqueeze(1))).detach().to(\n",
    "                        torch.float32).cpu().numpy()\n",
    "                kmeans_model = KMeans(n_clusters=options.n_clusters,\n",
    "                                      n_init='auto')\n",
    "\n",
    "                repeat = 50\n",
    "                best_inertia = np.zeros([3, repeat])\n",
    "                for rep in range(repeat):\n",
    "                    kmeans = kmeans_model.fit(H_normalized)\n",
    "                    try:\n",
    "                        y_prep = error_point(kmeans.labels_, y)[1]\n",
    "                    except Exception as e:\n",
    "                        y_prep = kmeans.labels_\n",
    "                    y_prep = y_prep.astype('int')\n",
    "                    ari = adjusted_rand_score(y, y_prep)\n",
    "                    nmi = normalized_mutual_info_score(y, y_prep)\n",
    "                    acc = accuracy_score(y, y_prep)\n",
    "                    if ari > best_accurancy[0]:\n",
    "                        best_label[0, :] = y_prep\n",
    "                    if nmi > best_accurancy[1]:\n",
    "                        best_label[1, :] = y_prep\n",
    "                    if acc > best_accurancy[2]:\n",
    "                        best_label[2, :] = y_prep\n",
    "                    best_inertia[:, rep] = np.array([ari, nmi, acc])\n",
    "\n",
    "                best_inertia = (np.max(best_inertia, axis=1)).tolist()\n",
    "                best_accurancy = np.maximum(best_inertia,\n",
    "                                            best_accurancy).tolist()\n",
    "\n",
    "                return best_accurancy, best_label, best_inertia, np.array(\n",
    "                    object_function)\n",
    "        else:\n",
    "            view_loss = torch.stack(view_loss)\n",
    "            loss_init = torch.sum(view_loss)\n",
    "            loss_list.append([orx_loss, view_loss])\n",
    "\n",
    "            connect_kernel.matrix = torch.nn.Parameter(\n",
    "                sum([(X_view[i] * singular_value[i]).detach().clone()\n",
    "                     for i in range(options.view_num)]) / options.view_num)\n",
    "            optimizers[\"optimizer_matrix\"] = optim.SGD([connect_kernel.matrix],\n",
    "                                                       lr=1e-2)\n",
    "        if torch.isnan(loss_init):\n",
    "            print(loss_list)\n",
    "            print((torch.diag(connect_view_k + connected_matrix)**0.5\n",
    "                   ).unsqueeze(1).detach().clone(), )\n",
    "            print(\"error\")\n",
    "            break\n",
    "\n",
    "        (loss_init + options.regular * reg_loss).backward()\n",
    "        if len(connect_loss) > 0:\n",
    "            object_function[epoch - options.init_time] = loss_init.item(\n",
    "            ) + options.view_num * options.gamma * torch.trace(\n",
    "                connected_matrix @ connected_matrix).item()\n",
    "            # update $\\Phi^\\star$ --------------------------------------------------------------------------------\n",
    "            connect_kernel.matrix.grad = torch.zeros(\n",
    "                [options.nSmp, options.n_clusters],\n",
    "                device=device,\n",
    "                dtype=torch.float32)\n",
    "            for i in range(options.view_num):\n",
    "                connect_kernel.matrix.grad += 2. * (1 + options.gamma) * (\n",
    "                    connect_kernel.matrix -\n",
    "                    X_view[i] * singular_value[i]).detach().clone()\n",
    "            orx_direction = 2. * (1 + options.gamma) * (\n",
    "                connect_kernel.matrix @ connect_kernel.matrix.T\n",
    "                @ connect_kernel.matrix -\n",
    "                connect_kernel.matrix).detach().clone()\n",
    "            norm_1 = torch.norm(connect_kernel.matrix.grad,\n",
    "                                dim=0).detach().clone()\n",
    "            norm_2 = torch.norm(orx_direction, dim=0).detach().clone()\n",
    "            cos_value = torch.diag(\n",
    "                connect_kernel.matrix.grad.T @ orx_direction) / norm_1 / norm_2\n",
    "            eta = 1. * (cos_value > options.eta) * options.eta * (norm_1 /\n",
    "                                                                  norm_2)\n",
    "            eta -= 1. * (cos_value < -options.eta) * options.eta * (norm_1 /\n",
    "                                                                    norm_2)\n",
    "            eta += 1. * (torch.abs(cos_value) <=\n",
    "                         options.eta) * cos_value * (norm_1 / norm_2)\n",
    "            connect_kernel.matrix.grad += orx_direction * eta\n",
    "            \n",
    "        old_loss = loss_init\n",
    "        if (epoch) % 25 == 0:\n",
    "\n",
    "            new_rank = torch.trace(connected_matrix).item() / torch.mean(\n",
    "                torch.stack(singular_value)).item()\n",
    "\n",
    "        if ((epoch) % 25 == 0) and epoch != 0:\n",
    "            if new_rank > 0.9 * old_rank:\n",
    "\n",
    "                H = connect_kernel.matrix.detach().clone()\n",
    "\n",
    "                H_normalized = ((H / (torch.maximum(\n",
    "                    torch.norm(H, dim=1),\n",
    "                    torch.ones(\n",
    "                        options.nSmp, device=device, dtype=torch.float32) *\n",
    "                    1e-15)).unsqueeze(1))).detach().to(\n",
    "                        torch.float32).cpu().numpy()\n",
    "                del H\n",
    "                kmeans_model = KMeans(n_clusters=options.n_clusters,\n",
    "                                      n_init='auto')\n",
    "\n",
    "                repeat = 50\n",
    "                best_inertia = np.zeros([3, repeat])\n",
    "                for rep in range(repeat):\n",
    "                    kmeans = kmeans_model.fit(H_normalized)\n",
    "                    try:\n",
    "                        y_prep = error_point(kmeans.labels_, y)[1]\n",
    "                    except Exception as e:\n",
    "                        y_prep = kmeans.labels_\n",
    "                    y_prep = y_prep.astype('int')\n",
    "                    ari = adjusted_rand_score(y, y_prep)\n",
    "                    nmi = normalized_mutual_info_score(y, y_prep)\n",
    "                    acc = accuracy_score(y, y_prep)\n",
    "                    if ari > best_accurancy[0]:\n",
    "                        best_label[0, :] = y_prep\n",
    "                    if nmi > best_accurancy[1]:\n",
    "                        best_label[1, :] = y_prep\n",
    "                    if acc > best_accurancy[2]:\n",
    "                        best_label[2, :] = y_prep\n",
    "                    best_inertia[:, rep] = np.array([ari, nmi, acc])\n",
    "\n",
    "                best_inertia = (np.max(best_inertia, axis=1)).tolist()\n",
    "                best_accurancy = np.maximum(best_inertia,\n",
    "                                            best_accurancy).tolist()\n",
    "\n",
    "\n",
    "            elif new_rank < 0.9 * old_rank and old_loss > old_inter_loss:\n",
    "                return best_accurancy, best_label, best_inertia, np.array(\n",
    "                    object_function)\n",
    "            old_rank = min(new_rank, options.n_clusters)\n",
    "\n",
    "        # update $\\Phi$ ------------------------------------------------------------------------------------\n",
    "        for optimizer_key, optimizer_value in zip(optimizers.keys(),\n",
    "                                                  optimizers.values()):\n",
    "            optimizer_value.step()\n",
    "            optimizer_value.zero_grad()\n",
    "        connect_kernel.matrix.grad = None\n",
    "        torch.cuda.empty_cache()\n",
    "    return best_accurancy, best_label, best_inertia, np.array(object_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 200\n",
      "1 200\n",
      "2 200\n",
      "3 200\n",
      "4 200\n",
      "5 200\n",
      "6 200\n",
      "7 200\n",
      "8 200\n",
      "9 200\n",
      "6 (2000, 240)\n",
      "6.2 9\n",
      "6.421 9\n",
      "6.451 9\n",
      "6.629 9\n",
      "6.517 9\n",
      "6.553 7\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "class HiddenPrints:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout\n",
    "\n",
    "# Initial\n",
    "datasets_path = \"./datasets\"\n",
    "file_name = \"YALE.mat\"\n",
    "data = load_data(datasets_path + '/' + file_name)\n",
    "torch.cuda.empty_cache()\n",
    "EmptyStruct = type('EmptyStruct', (), {})\n",
    "options = EmptyStruct()\n",
    "n_clusters = len(np.unique(data.y))\n",
    "for i in range(n_clusters):\n",
    "    print(\n",
    "        np.unique(data.y)[i], len(np.where(data.y == np.unique(data.y)[i])[0]))\n",
    "\n",
    "options.n_clusters = n_clusters\n",
    "view_num = len(data.x)\n",
    "\n",
    "options.view_num = view_num\n",
    "nSmp = data.x[0].shape[0]\n",
    "options.nSmp = nSmp\n",
    "options.layer_width_c = [\n",
    "    nSmp,\n",
    "    max([min([int(nSmp**0.5), int(nSmp / n_clusters)]), n_clusters]),\n",
    "    n_clusters\n",
    "]\n",
    "options.init_time = 300\n",
    "options.maxIter = 1000\n",
    "Sigma = np.ones(view_num) / view_num\n",
    "options.threshold = 0.45\n",
    "options.regular = 1e-3\n",
    "options.con = 1e0\n",
    "options.peak_num = n_clusters * 2\n",
    "print(view_num, data.x[0].shape)\n",
    "\n",
    "options.knn = []\n",
    "options.min_k = 3\n",
    "\n",
    "# normalize kernel matrix\n",
    "K = []\n",
    "normal_X = []\n",
    "for i in range(view_num):\n",
    "    if file_name[-5] == 'K':\n",
    "        TempK = data.x[i]\n",
    "        TempK = kcenter(TempK)\n",
    "        TempK = TempK / (np.diag(TempK)**0.5).reshape([options.nSmp, 1]) / (\n",
    "            np.diag(TempK)**0.5).reshape([options.nSmp, 1]).T\n",
    "        TempD = np.abs(np.sum(TempK, axis=1, keepdims=True))**-.5\n",
    "        V, D = eigsh(TempK * TempD * TempD.T, k=options.n_clusters, which='LA')\n",
    "        print(i, V)\n",
    "        K.append(TempK / V[-1])\n",
    "        options.knn.append(\n",
    "            adapted_neighbor(TempK / V[-1], options.min_k, options.n_clusters))\n",
    "        del TempK\n",
    "    elif data.x[i].shape[1] == data.x[i].shape[0]:\n",
    "        print('distance_data')\n",
    "        TempK = data.x[i]\n",
    "        t = np.mean(np.mean(TempK))\n",
    "        TempK = np.exp(-TempK**2 / (2 * t**2))\n",
    "        K.append(TempK)\n",
    "        options.knn.append(\n",
    "            adapted_neighbor(TempK, options.min_k, options.n_clusters))\n",
    "        del TempK\n",
    "    else:\n",
    "        temp_x = NormalizeData(data.x[i])\n",
    "        TempK = pairwise_distances(temp_x, metric='euclidean')\n",
    "        # logic_knn, knn = generateNeighborhood(-TempK, knn_k)\n",
    "        t = np.mean(np.mean(TempK))\n",
    "        TempK = np.exp(-TempK**2 / (2 * t**2))\n",
    "        K.append(TempK)\n",
    "        options.knn.append(\n",
    "            adapted_neighbor(TempK, options.min_k, options.n_clusters))\n",
    "        del TempK, temp_x  #mean_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(7.4622, device='cuda:0'), tensor(7.4738, device='cuda:0'), tensor(7.5251, device='cuda:0'), tensor(7.4852, device='cuda:0'), tensor(7.4294, device='cuda:0'), tensor(6.7613, device='cuda:0')]\n",
      "[tensor(77.0325, device='cuda:0'), tensor(57.9800, device='cuda:0'), tensor(65.1734, device='cuda:0'), tensor(67.0208, device='cuda:0'), tensor(76.0557, device='cuda:0'), tensor(63.1677, device='cuda:0')]\n",
      "25: [0.4907018813681303, 0.5949449609861407, 0.667] [0.4907018813681303, 0.5949449609861407, 0.667] [0.47112985883866004, 0.5822210139822191, 0.6409999999999999]\n",
      "[tensor(77.4816, device='cuda:0'), tensor(56.9153, device='cuda:0'), tensor(66.4789, device='cuda:0'), tensor(66.4746, device='cuda:0'), tensor(77.9712, device='cuda:0'), tensor(59.5685, device='cuda:0')]\n",
      "50: [0.7099640912007266, 0.7898720891999796, 0.8185] [0.7099640912007266, 0.7898720891999796, 0.8185] [0.6507482465761316, 0.748751663029362, 0.7598999999999999]\n",
      "[tensor(78.1504, device='cuda:0'), tensor(60.8692, device='cuda:0'), tensor(65.0548, device='cuda:0'), tensor(67.2864, device='cuda:0'), tensor(78.5526, device='cuda:0'), tensor(64.5265, device='cuda:0')]\n",
      "75: [0.7623376032488905, 0.8457380610246891, 0.8185] [0.7623376032488905, 0.8457380610246891, 0.8155] [0.7085165064221448, 0.803270665716721, 0.80414]\n",
      "[tensor(63.9997, device='cuda:0'), tensor(51.5546, device='cuda:0'), tensor(54.8730, device='cuda:0'), tensor(54.7938, device='cuda:0'), tensor(64.1712, device='cuda:0'), tensor(53.1361, device='cuda:0')]\n",
      "100: [0.7857650700733189, 0.8619793095155887, 0.864] [0.7857650700733189, 0.8619793095155887, 0.864] [0.7760384334410433, 0.8483017471506336, 0.84724]\n",
      "[tensor(52.7255, device='cuda:0'), tensor(43.3925, device='cuda:0'), tensor(45.6989, device='cuda:0'), tensor(45.3012, device='cuda:0'), tensor(52.6842, device='cuda:0'), tensor(44.3561, device='cuda:0')]\n",
      "125: [0.8120550503487891, 0.8743485087029242, 0.8775] [0.8120550503487891, 0.8743485087029242, 0.8775] [0.8019908853932258, 0.8642198134804935, 0.8641900000000001]\n",
      "[tensor(44.6811, device='cuda:0'), tensor(37.1595, device='cuda:0'), tensor(38.8408, device='cuda:0'), tensor(38.5720, device='cuda:0'), tensor(44.5265, device='cuda:0'), tensor(38.1996, device='cuda:0')]\n",
      "150: [0.8295223275813451, 0.8870678955637779, 0.888] [0.8295223275813451, 0.8870678955637779, 0.888] [0.8216627520415105, 0.8748743679273325, 0.8721800000000001]\n",
      "[tensor(38.4047, device='cuda:0'), tensor(32.1941, device='cuda:0'), tensor(33.3822, device='cuda:0'), tensor(33.1955, device='cuda:0'), tensor(38.1626, device='cuda:0'), tensor(33.3768, device='cuda:0')]\n",
      "175: [0.8420639778946047, 0.8976352301367662, 0.8935] [0.8420639778946047, 0.8976352301367662, 0.8935] [0.8356496378939735, 0.8829537902414282, 0.8855]\n",
      "[tensor(33.4036, device='cuda:0'), tensor(28.2101, device='cuda:0'), tensor(29.0406, device='cuda:0'), tensor(28.8808, device='cuda:0'), tensor(33.1454, device='cuda:0'), tensor(29.5169, device='cuda:0')]\n",
      "200: [0.8476282260926079, 0.9071346838623857, 0.896] [0.8476282260926079, 0.9071346838623857, 0.896] [0.8364358573607434, 0.8860352882165113, 0.8836499999999998]\n",
      "[tensor(29.3395, device='cuda:0'), tensor(24.9696, device='cuda:0'), tensor(25.5059, device='cuda:0'), tensor(25.4038, device='cuda:0'), tensor(29.0943, device='cuda:0'), tensor(26.3635, device='cuda:0')]\n",
      "225: [0.8476282260926079, 0.9071346838623857, 0.897] [0.8444621912946492, 0.9014633508985501, 0.897] [0.834391062347877, 0.8868811375942056, 0.8796599999999999]\n",
      "[tensor(26.0035, device='cuda:0'), tensor(22.2771, device='cuda:0'), tensor(22.6236, device='cuda:0'), tensor(22.5336, device='cuda:0'), tensor(25.7703, device='cuda:0'), tensor(23.7264, device='cuda:0')]\n",
      "250: [0.8477475631319988, 0.9071346838623857, 0.8995] [0.8477475631319988, 0.9061302700425856, 0.8995] [0.8383987176946576, 0.8911616647887501, 0.8807699999999999]\n",
      "[tensor(23.2347, device='cuda:0'), tensor(20.0189, device='cuda:0'), tensor(20.2119, device='cuda:0'), tensor(20.1183, device='cuda:0'), tensor(23.0199, device='cuda:0'), tensor(21.4827, device='cuda:0')]\n",
      "275: [0.8504894374740601, 0.9089901817510126, 0.9025] [0.8504894374740601, 0.9089901817510126, 0.9025] [0.849379864294114, 0.895056001060563, 0.8985400000000001]\n",
      "[tensor(20.8962, device='cuda:0'), tensor(18.0899, device='cuda:0'), tensor(18.1749, device='cuda:0'), tensor(18.0740, device='cuda:0'), tensor(20.6884, device='cuda:0'), tensor(19.5711, device='cuda:0')]\n",
      "300: [0.8522083080375434, 0.9112831603609591, 0.9045] [0.8522083080375434, 0.9112831603609591, 0.9045] [0.84604158341843, 0.894342933896987, 0.89331]\n",
      "[tensor(20.1474, device='cuda:0'), tensor(17.8400, device='cuda:0'), tensor(16.5872, device='cuda:0'), tensor(17.7942, device='cuda:0'), tensor(19.8967, device='cuda:0'), tensor(16.8394, device='cuda:0')]\n",
      "325: [0.857131275656707, 0.9186174902159909, 0.9045] [0.857131275656707, 0.9186174902159909, 0.903] [0.8500423440182635, 0.8973338113322384, 0.8968900000000001]\n",
      "[tensor(18.6777, device='cuda:0'), tensor(16.4876, device='cuda:0'), tensor(15.3193, device='cuda:0'), tensor(16.4532, device='cuda:0'), tensor(18.4170, device='cuda:0'), tensor(15.7843, device='cuda:0')]\n",
      "350: [0.8590184974579141, 0.9186174902159909, 0.9045] [0.8590184974579141, 0.9180415312528168, 0.8985] [0.8493294342212359, 0.8964458675919353, 0.8965700000000001]\n",
      "[tensor(17.1316, device='cuda:0'), tensor(15.1818, device='cuda:0'), tensor(14.0087, device='cuda:0'), tensor(15.1057, device='cuda:0'), tensor(16.8608, device='cuda:0'), tensor(14.7060, device='cuda:0')]\n",
      "375: [0.8590184974579141, 0.9186174902159909, 0.9045] [0.8480704703394208, 0.9141114294680848, 0.897] [0.8461162658237719, 0.8932587160867118, 0.8944]\n",
      "[tensor(15.7542, device='cuda:0'), tensor(14.0202, device='cuda:0'), tensor(12.8805, device='cuda:0'), tensor(13.9347, device='cuda:0'), tensor(15.4850, device='cuda:0'), tensor(13.6858, device='cuda:0')]\n",
      "400: [0.8607050421088525, 0.9201575670810893, 0.9045] [0.8607050421088525, 0.9201575670810893, 0.894] [0.847086428704008, 0.8947857532746665, 0.89178]\n",
      "[tensor(14.5872, device='cuda:0'), tensor(13.0124, device='cuda:0'), tensor(11.9148, device='cuda:0'), tensor(12.8983, device='cuda:0'), tensor(14.3264, device='cuda:0'), tensor(12.7350, device='cuda:0')]\n",
      "425: [0.8607050421088525, 0.9201575670810893, 0.9045] [0.8596510773676311, 0.9191055019203128, 0.8915] [0.846083153055758, 0.893878645712509, 0.88923]\n",
      "[tensor(13.5446, device='cuda:0'), tensor(12.0992, device='cuda:0'), tensor(11.0349, device='cuda:0'), tensor(11.9713, device='cuda:0'), tensor(13.2960, device='cuda:0'), tensor(11.8871, device='cuda:0')]\n",
      "450: [0.8607050421088525, 0.9207824729640922, 0.9045] [0.8592141234773573, 0.9207824729640922, 0.8915] [0.8468055366914465, 0.8940145345691889, 0.8900799999999998]\n",
      "[tensor(12.6288, device='cuda:0'), tensor(11.2623, device='cuda:0'), tensor(10.2712, device='cuda:0'), tensor(11.1344, device='cuda:0'), tensor(12.4047, device='cuda:0'), tensor(11.1258, device='cuda:0')]\n",
      "475: [0.8607050421088525, 0.9210260764362568, 0.9045] [0.8602000517314519, 0.9210260764362568, 0.8905] [0.8472331987735074, 0.893954795531957, 0.8899700000000001]\n",
      "[tensor(11.8401, device='cuda:0'), tensor(10.5315, device='cuda:0'), tensor(9.6166, device='cuda:0'), tensor(10.3936, device='cuda:0'), tensor(11.6225, device='cuda:0'), tensor(10.4433, device='cuda:0')]\n",
      "500: [0.8607050421088525, 0.9210260764362568, 0.9045] [0.8543233222586956, 0.9159106430885744, 0.888] [0.8454847290236175, 0.8923199601190857, 0.88727]\n",
      "[tensor(11.1033, device='cuda:0'), tensor(9.8856, device='cuda:0'), tensor(8.9987, device='cuda:0'), tensor(9.7228, device='cuda:0'), tensor(10.8996, device='cuda:0'), tensor(9.8219, device='cuda:0')]\n",
      "525: [0.8607050421088525, 0.9210260764362568, 0.9045] [0.8528614188629169, 0.9149037516223669, 0.8875] [0.8453550932122783, 0.8922543125707364, 0.8867700000000002]\n",
      "[tensor(10.4191, device='cuda:0'), tensor(9.2788, device='cuda:0'), tensor(8.4263, device='cuda:0'), tensor(9.1020, device='cuda:0'), tensor(10.2317, device='cuda:0'), tensor(9.2507, device='cuda:0')]\n",
      "550: [0.8607050421088525, 0.9210260764362568, 0.9045] [0.8582091087830924, 0.9193927415449293, 0.887] [0.8434707634125023, 0.8913456540691697, 0.8834700000000001]\n",
      "[tensor(9.8149, device='cuda:0'), tensor(8.7423, device='cuda:0'), tensor(7.9157, device='cuda:0'), tensor(8.5557, device='cuda:0'), tensor(9.6383, device='cuda:0'), tensor(8.7475, device='cuda:0')]\n",
      "575: [0.8607050421088525, 0.9210260764362568, 0.9045] [0.84813485283239, 0.9143888274485431, 0.8855] [0.8430224730534777, 0.891360959466927, 0.8825500000000001]\n",
      "[tensor(9.2518, device='cuda:0'), tensor(8.2395, device='cuda:0'), tensor(7.4506, device='cuda:0'), tensor(8.0516, device='cuda:0'), tensor(9.0874, device='cuda:0'), tensor(8.2785, device='cuda:0')]\n",
      "600: [0.8607050421088525, 0.9210260764362568, 0.9045] [0.8448842942169023, 0.8914378329493288, 0.8855] [0.8429253034330909, 0.8903257355221769, 0.8830500000000001]\n",
      "[tensor(8.7334, device='cuda:0'), tensor(7.7775, device='cuda:0'), tensor(7.0261, device='cuda:0'), tensor(7.5894, device='cuda:0'), tensor(8.5785, device='cuda:0'), tensor(7.8522, device='cuda:0')]\n",
      "625: [0.8607050421088525, 0.9210260764362568, 0.9045] [0.8518682709523143, 0.9138519507293298, 0.8855] [0.8441151705331594, 0.8914066415180801, 0.8843999999999999]\n",
      "[tensor(8.2688, device='cuda:0'), tensor(7.3583, device='cuda:0'), tensor(6.6389, device='cuda:0'), tensor(7.1650, device='cuda:0'), tensor(8.1205, device='cuda:0'), tensor(7.4665, device='cuda:0')]\n",
      "650: [0.8607050421088525, 0.9210260764362568, 0.9045] [0.8548964409587702, 0.9146094749770964, 0.8845] [0.844389245168784, 0.8927014923370047, 0.8830600000000001]\n",
      "[tensor(7.8441, device='cuda:0'), tensor(6.9762, device='cuda:0'), tensor(6.2880, device='cuda:0'), tensor(6.7815, device='cuda:0'), tensor(7.7017, device='cuda:0'), tensor(7.0993, device='cuda:0')]\n",
      "675: [0.8607050421088525, 0.9210260764362568, 0.9045] [0.8526172695226409, 0.9142809466931139, 0.8845] [0.8438974270282701, 0.8908209406397805, 0.8842699999999999]\n",
      "[tensor(7.4419, device='cuda:0'), tensor(6.6174, device='cuda:0'), tensor(5.9557, device='cuda:0'), tensor(6.4199, device='cuda:0'), tensor(7.3040, device='cuda:0'), tensor(6.7636, device='cuda:0')]\n",
      "700: [0.8607050421088525, 0.9210260764362568, 0.9045] [0.8539236249089244, 0.9143888274485431, 0.8845] [0.8421408234291868, 0.8923283799760017, 0.87987]\n",
      "[tensor(7.0786, device='cuda:0'), tensor(6.2886, device='cuda:0'), tensor(5.6540, device='cuda:0'), tensor(6.0910, device='cuda:0'), tensor(6.9468, device='cuda:0'), tensor(6.4544, device='cuda:0')]\n",
      "725: [0.8607050421088525, 0.9210260764362568, 0.9045] [0.8526172695226409, 0.9143888274485431, 0.8845] [0.8440367709566725, 0.8928586018397442, 0.88185]\n",
      "[tensor(6.7374, device='cuda:0'), tensor(5.9854, device='cuda:0'), tensor(5.3732, device='cuda:0'), tensor(5.7868, device='cuda:0'), tensor(6.6122, device='cuda:0'), tensor(6.1653, device='cuda:0')]\n",
      "750: [0.8607050421088525, 0.9210260764362568, 0.9045] [0.8529480743197518, 0.912472777578964, 0.884] [0.8438532798399007, 0.8904907446807158, 0.88381]\n",
      "[tensor(6.4192, device='cuda:0'), tensor(5.6977, device='cuda:0'), tensor(5.1127, device='cuda:0'), tensor(5.5066, device='cuda:0'), tensor(6.2946, device='cuda:0'), tensor(5.8990, device='cuda:0')]\n",
      "775: [0.8607050421088525, 0.9210260764362568, 0.9045] [0.8552116670098089, 0.9184570265966134, 0.884] [0.8441828133962878, 0.8919872569498672, 0.88262]\n",
      "[tensor(6.1338, device='cuda:0'), tensor(5.4377, device='cuda:0'), tensor(4.8757, device='cuda:0'), tensor(5.2463, device='cuda:0'), tensor(6.0114, device='cuda:0'), tensor(5.6505, device='cuda:0')]\n",
      "800: [0.8607050421088525, 0.9210260764362568, 0.9045] [0.8518682709523143, 0.9140355134228461, 0.8835] [0.8433626861964928, 0.8909599666688007, 0.88226]\n",
      "[tensor(5.8634, device='cuda:0'), tensor(5.1921, device='cuda:0'), tensor(4.6517, device='cuda:0'), tensor(5.0075, device='cuda:0'), tensor(5.7442, device='cuda:0'), tensor(5.4204, device='cuda:0')]\n",
      "825: [0.8607050421088525, 0.9210260764362568, 0.9045] [0.8508809581140178, 0.9140355134228461, 0.883] [0.8428231838876892, 0.8904871349423772, 0.8820800000000001]\n",
      "[tensor(5.6180, device='cuda:0'), tensor(4.9693, device='cuda:0'), tensor(4.4488, device='cuda:0'), tensor(4.7853, device='cuda:0'), tensor(5.5016, device='cuda:0'), tensor(5.2103, device='cuda:0')]\n",
      "850: [0.8607050421088525, 0.9210260764362568, 0.9045] [0.8549777840774716, 0.9150163406943984, 0.883] [0.8431432890095499, 0.8910204707718523, 0.8818900000000002]\n",
      "[tensor(5.3850, device='cuda:0'), tensor(4.7460, device='cuda:0'), tensor(4.2543, device='cuda:0'), tensor(4.5712, device='cuda:0'), tensor(5.2749, device='cuda:0'), tensor(5.0067, device='cuda:0')]\n",
      "875: [0.8607050421088525, 0.9210260764362568, 0.9045] [0.8564681367491856, 0.9176165066322408, 0.883] [0.8433618649795579, 0.8916389231650425, 0.8816400000000002]\n",
      "[tensor(5.1652, device='cuda:0'), tensor(4.5477, device='cuda:0'), tensor(4.0698, device='cuda:0'), tensor(4.3748, device='cuda:0'), tensor(5.0591, device='cuda:0'), tensor(4.8189, device='cuda:0')]\n",
      "900: [0.8607050421088525, 0.9210260764362568, 0.9045] [0.854514565508668, 0.9178107666548198, 0.883] [0.8409230733010369, 0.8898922556668073, 0.87952]\n",
      "[tensor(4.9593, device='cuda:0'), tensor(4.3617, device='cuda:0'), tensor(3.8994, device='cuda:0'), tensor(4.1918, device='cuda:0'), tensor(4.8562, device='cuda:0'), tensor(4.6414, device='cuda:0')]\n",
      "925: [0.8607050421088525, 0.9210260764362568, 0.9045] [0.8533538304779409, 0.9132529253564725, 0.8825] [0.8407014123443796, 0.888361146892229, 0.8801399999999999]\n",
      "[tensor(4.7671, device='cuda:0'), tensor(4.1808, device='cuda:0'), tensor(3.7418, device='cuda:0'), tensor(4.0221, device='cuda:0'), tensor(4.6666, device='cuda:0'), tensor(4.4734, device='cuda:0')]\n",
      "950: [0.8607050421088525, 0.9210260764362568, 0.9045] [0.8476438717837895, 0.9142156456776007, 0.8825] [0.8423851163049986, 0.8890030710538517, 0.8819399999999998]\n",
      "[tensor(4.5895, device='cuda:0'), tensor(4.0217, device='cuda:0'), tensor(3.5957, device='cuda:0'), tensor(3.8630, device='cuda:0'), tensor(4.4928, device='cuda:0'), tensor(4.3202, device='cuda:0')]\n",
      "975: [0.8607050421088525, 0.9210260764362568, 0.9045] [0.8508809581140178, 0.913016252491616, 0.8825] [0.8427990332799675, 0.8902236380126994, 0.8816399999999999]\n",
      "converage\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8607050421088525, 0.9210260764362568, 0.9045]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options.alpha = 1\n",
    "options.beta = 0\n",
    "options.eta = 0.1\n",
    "options.gamma = 1e-1\n",
    "init_Kernel_train(data.y, K, options)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
